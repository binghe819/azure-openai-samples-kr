{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# OpenAI Quickstart"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Overview  \n",
        "\"Large Language Model은 텍스트를 텍스트에 매핑하는 기능입니다. 입력 문자열이 주어지면 큰 언어 모델은 다음에 올 텍스트를 예측하려고합니다\"(1).이 \"QuickStart\"노트북은 사용자에게 고급 LLM 개념, AML을 시작하기위한 핵심 패키지 요구 사항, 프롬프트 설계를위한 소프트 소개 및 다양한 사용 사례의 Severa 짧은 예를 소개합니다.\n",
        "\n",
        "For more quickstart examples please refer to the official Azure Open AI Quickstart Documentation https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Table of Contents  \n",
        "\n",
        "[Overview](#overview)  \n",
        "[How to use OpenAI Service](#how-to-use-openai-service)  \n",
        "[1. Creating your OpenAI Service](#1.-creating-your-openai-service)  \n",
        "[2. Installation](#2.-installation)    \n",
        "[3. Credentials](#3.-credentials)  \n",
        "\n",
        "[Use Cases](#use-cases)    \n",
        "[1. Summarize Text](#1.-summarize-text)  \n",
        "[2. Classify Text](#2.-classify-text)  \n",
        "[3. Generate New Product Names](#3.-generate-new-product-names)  \n",
        "[4. Fine Tune a Classifier](#4.fine-tune-a-classifier)  \n",
        "[5. Embeddings!]((#5.-embeddings!))\n",
        "\n",
        "[References](#references)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Getting started with Azure OpenAI Service\n",
        "\n",
        "신규 고객은 Azure OpenAi 서비스에 [https://aka.ms/oai/access) [액세스 신청] (https://aka.ms/oai/access)해야합니다.\n",
        "승인이 완료된 후 고객은 Azure Portal에 로그인하고 Azure OpenAI 서비스 리소스를 만들고 스튜디오를 통해 모델 실험을 시작할 수 있습니다.\n",
        "\n",
        "[Great resource for getting started quickly](https://techcommunity.microsoft.com/t5/educator-developer-blog/azure-openai-is-now-generally-available/ba-p/3719177 )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Build your first prompt  \n",
        "이 짧은 연습은 간단한 작업 \"요약\"을 위해 OpenAI 모델에 프롬프트를 제출하기위한 기본 소개를 제공합니다.\n",
        "\n",
        "![](images/generative-AI-models-reduced.jpg)  \n",
        "\n",
        "\n",
        "**Steps**:  \n",
        "1. 파이썬 환경에 OpenAI 라이브러리를 설치하십시오\n",
        "2. 표준 도우미 라이브러리를로드하고 만든 OpenAI 서비스에 대한 일반적인 OpenAI 보안 자격 증명을 설정하십시오.\n",
        "3. 작업에 대한 모델을 선택하십시오\n",
        "4. 모델에 대한 간단한 프롬프트를 만듭니다\n",
        "5. 모델 API에 요청을 제출하십시오!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1. Install OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674254990318
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: azure-search-documents==11.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: num2words==0.5.12 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (0.5.12)\n",
            "Requirement already satisfied: openai==0.27.2 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (0.27.2)\n",
            "Requirement already satisfied: pdfminer==20191125 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (20191125)\n",
            "Requirement already satisfied: plotly==5.10.0 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (5.10.0)\n",
            "Requirement already satisfied: transformers==4.5.1 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (4.5.1)\n",
            "Requirement already satisfied: sklearn==0.0.post5 in /home/vscode/.local/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (0.0.post5)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.19.0 in /home/vscode/.local/lib/python3.9/site-packages (from azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (1.28.0)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /home/vscode/.local/lib/python3.9/site-packages (from azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: azure-common~=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (1.1.28)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vscode/.local/lib/python3.9/site-packages (from azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (4.7.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /home/vscode/.local/lib/python3.9/site-packages (from num2words==0.5.12->-r ../requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.20 in /home/vscode/.local/lib/python3.9/site-packages (from openai==0.27.2->-r ../requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /home/vscode/.local/lib/python3.9/site-packages (from openai==0.27.2->-r ../requirements.txt (line 4)) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /home/vscode/.local/lib/python3.9/site-packages (from openai==0.27.2->-r ../requirements.txt (line 4)) (3.8.4)\n",
            "Requirement already satisfied: pycryptodome in /home/vscode/.local/lib/python3.9/site-packages (from pdfminer==20191125->-r ../requirements.txt (line 5)) (3.18.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /home/vscode/.local/lib/python3.9/site-packages (from plotly==5.10.0->-r ../requirements.txt (line 6)) (8.2.2)\n",
            "Requirement already satisfied: filelock in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (3.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (1.25.1)\n",
            "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (2023.6.3)\n",
            "Requirement already satisfied: sacremoses in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (0.0.53)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/vscode/.local/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 7)) (0.10.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /home/vscode/.local/lib/python3.9/site-packages (from azure-core<2.0.0,>=1.19.0->azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.9/site-packages (from msrest>=0.6.21->azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (2023.5.7)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /home/vscode/.local/lib/python3.9/site-packages (from msrest>=0.6.21->azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /home/vscode/.local/lib/python3.9/site-packages (from msrest>=0.6.21->azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.9/site-packages (from requests>=2.20->openai==0.27.2->-r ../requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.9/site-packages (from requests>=2.20->openai==0.27.2->-r ../requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.9/site-packages (from requests>=2.20->openai==0.27.2->-r ../requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai==0.27.2->-r ../requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: click in /home/vscode/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.5.1->-r ../requirements.txt (line 7)) (8.1.4)\n",
            "Requirement already satisfied: joblib in /home/vscode/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.5.1->-r ../requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/vscode/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-search-documents==11.3.0->-r ../requirements.txt (line 2)) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ../requirements.txt\n",
        "# pip install openai python-dotenv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2. Import helper libraries and instantiate credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1674829434433
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_version = \"2023-06-01-preview\"\n",
        "\n",
        "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\").strip()\n",
        "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
        "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
        "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
        "openai.api_base = RESOURCE_ENDPOINT"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 3. Finding the right model  \n",
        "GPT-3 모델은 자연어를 이해하고 생성 할 수 있습니다.이 서비스는 각각 다른 수준의 전력과 속도를 가진 4 가지 모델 기능을 제공합니다. Davinci는 가장 유능한 모델이며 Ada는 가장 빠릅니다.다음 목록은 기능을 증가시켜 주문한 최신 버전의 GPT-3 모델을 나타냅니다 (1).\n",
        "* ~~text-ada-001~~\n",
        "* ~~text-babbage-001~~\n",
        "* ~~text-curie-001~~\n",
        "* ~~text-davinci-003~~\n",
        "였으나, 지금은 다 내려가 있고, 다른 모델을 쓸 거에요.\n",
        "\n",
        "[Azure OpenAI models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models)  \n",
        "![](images/a-b-c-d-models-reduced.jpg)  \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Model Taxonomy  \n",
        "Let's choose a general text GPT-3 model, using the second most powerful model (Curie)\n",
        "\n",
        "**Model taxonomy**: {family} - {capability} - {input-type} - {identifier}  \n",
        "\n",
        "{family}     --> text   (general text GPT-3 model)  \n",
        "{capability} --> curie  (curie is second most powerful in ada-babbage-curie-davinci family)  \n",
        "{input-type} --> n/a    (only specified for search models)  \n",
        "{identifier} --> 001    (version 001)  \n",
        "\n",
        "model = \"text-curie-001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1674742720788
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Select the General Purpose curie model for text\n",
        "model = \"gpt-35-turbo\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4. Prompt Design  \n",
        "\n",
        "\"LLM의 마술은 방대한 양의 텍스트 보다 예측 오류를 최소화하도록 훈련함으로써 모델이 이러한 예측에 유용한 학습 개념을 끝내는 것입니다. 예를 들어, 그들은\"(1) :과 같은 개념을 학습한다는 것입니다.\n",
        "\n",
        "* 어떻게 쓰는지\n",
        "* 문법의 작동 방식\n",
        "* 역설하는 방법\n",
        "* 질문에 대답하는 방법\n",
        "* 대화를하는 방법\n",
        "* 많은 언어로 작성하는 방법\n",
        "* 코딩 방법\n",
        "* 등.\n",
        "\n",
        "#### How to control a large language model  \n",
        "\"LLM에 대한 모든 입력 중에서 가장 영향력있는 것은 텍스트 프롬프트 (1)입니다.\n",
        "\n",
        "Large language models can be prompted to produce output in a few ways:\n",
        "\n",
        "Instruction: 모델에 원하는 것을 말하십시오\n",
        "Completion: 모델이 원하는 것의 시작을 완료하도록 유도\n",
        "Demonstration: 다음 중 하나와 함께 모델에 원하는 것을 표시하십시오.\n",
        "프롬프트의 몇 가지 예\n",
        "미세 조정 훈련 데이터 세트의 수백 또는 수천 가지 예제 \"\n",
        "\n",
        "\n",
        "\n",
        "#### There are three basic guidelines to creating prompts:\n",
        "\n",
        "**Show and tell**. 지침, 예제 또는 두 가지의 조합을 통해 원하는 것을 분명히하십시오.모델이 알파벳 순서로 항목 목록을 순위에 올리거나 정서적으로 단락을 분류하려면 원하는 것임을 보여주십시오.\n",
        "\n",
        "**Provide quality data**. 분류기를 구축하거나 모델이 패턴을 따를 경우 충분한 예가 있는지 확인하십시오.예제를 교정하십시오. 모델은 일반적으로 기본 철자 실수를 통해 보고 응답을 제공 할 수있을 정도로 똑똑하지만 의도적이며 응답에 영향을 줄 수 있다고 가정 할 수도 있습니다.\n",
        "\n",
        "**Check your settings.** 온도 및 TOP_P 설정은 모델이 응답을 생성하는 데 결정적인 방법을 제어합니다.정답이 하나만있는 응답을 요청하는 경우 더 낮게 설정하고 싶을 것입니다.더 다양한 응답을 찾고 있다면 더 높은 응답을 원할 수도 있습니다.사람들이 이러한 설정에서 사용하는 가장 큰 실수는 그들이 \"영리\"또는 \"창의성\"컨트롤을 가정합니다.\n",
        "\n",
        "\n",
        "Source: https://github.com/Azure/OpenAI/blob/main/How%20to/Completions.md"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "![](images/prompt_design.jpg)\n",
        "image is creating your first text prompt!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 5. Submit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1674494935186
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create your first prompt\n",
        "system_prompt = \"\"\"\n",
        "너는 가게 리뷰를 보고 긍정, 부정을 판별할 수 있는 리뷰 감정사야. 각 리뷰를 보고 긍정과 부정의 정도를 나타내는 점수도 판별할 수 있어.\n",
        "이제 아래 ```에 리뷰 데이터를 줄거야. 한줄당 긍정, 부정을 판별해서 각각의 점수를 알려줘. 형식은 \"긍정{점수}\", \"부정{점수}\" 형태로 알려줘.\n",
        "한글로 번역해서 알려줘.\n",
        "\"\"\"\n",
        "\n",
        "text_prompt = \"\"\"\n",
        "```\n",
        "1\t맛있게 잘먹었어요 탕수육이 고기가 엄청 두툼하고 튀김옷이 얇아서 맛있어요 마라탕도 즐겨먹진 않는데 먹을수록 더 당기네요\n",
        "2\t탕수육전문점에게 항상 아쉬웠던게 짬뽕이 없다는 거였는데, 여긴 짬뽕 팔아서 너무 좋더라구요. 첨엔 면이 없어서 전화하려다 자세히보니 짬뽕이 아니라 짬뽕탕 였어요 ㅎㅎ 면사리 넣어 냄비에 한번 더 끊여 먹으니 맛있더라구요. 근데 오늘은 짬뽕보다 저번에 먹었던 만두가 너무 맛있길래 만두땜에 재주문 했습니다. 만두 꼭 시켜 드세요. 맛있어요. 멘보샤도 작긴 하지만 새우향 싹 올라오면서 가격에 비해 엄청 혜자메뉴 입니다. 탕수육 전문점이니 탕수육은 기본으로 맛있어요 젤 작은거 시켰는데, 꽉찬 고기 고려해서 보니 정말 저렴하게 파시는듯. 메뉴 시키는거마다 맛있고 가성비가 좋아요.\n",
        "3\t사진 못 찍어서 먹다가 찍었네용 ㅜ 잘 먹었습니다...!\n",
        "4\t김피탕이 생각나 시켜먹었는데 넘모맛있어요 고기가 토실토실해요덕분에 제 배도 토실토실해요\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1674494938225
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "InvalidRequestError",
          "evalue": "The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Simple API Call\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      3\u001b[0m     engine\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      4\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m8191\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      6\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: system_prompt},\n\u001b[1;32m      7\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: text_prompt}\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[1;32m      9\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
          ]
        }
      ],
      "source": [
        "# Simple API Call\n",
        "openai.ChatCompletion.create(\n",
        "    engine=model,\n",
        "    max_tokens=8191,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": text_prompt}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Repeat the same call, how do the results compare?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674494940872
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7bT3OiYIJkjK891VXQkb6j2OstkRG at 0x7f8de8435a90> JSON: {\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"content_filter_results\": {\n",
              "        \"hate\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"self_harm\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"sexual\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"violence\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        }\n",
              "      },\n",
              "      \"finish_reason\": \"length\",\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"content\": \"1. The sweet and sour pork was delicious. The meat was thick and the coating was thin and crispy. I don't usually enjoy spicy hot pot, but I kept craving it more and more as I ate.\\n\\n2. I always felt disappointed that the pork sweet and sour restaurants didn't offer spicy\",\n",
              "        \"role\": \"assistant\"\n",
              "      }\n",
              "    }\n",
              "  ],\n",
              "  \"created\": 1689164174,\n",
              "  \"id\": \"chatcmpl-7bT3OiYIJkjK891VXQkb6j2OstkRG\",\n",
              "  \"model\": \"gpt-35-turbo\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"prompt_annotations\": [\n",
              "    {\n",
              "      \"content_filter_results\": {\n",
              "        \"hate\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"self_harm\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"sexual\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        },\n",
              "        \"violence\": {\n",
              "          \"filtered\": false,\n",
              "          \"severity\": \"safe\"\n",
              "        }\n",
              "      },\n",
              "      \"prompt_index\": 0\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"completion_tokens\": 60,\n",
              "    \"prompt_tokens\": 956,\n",
              "    \"total_tokens\": 1016\n",
              "  }\n",
              "}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.ChatCompletion.create(\n",
        "    engine=model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": text_prompt},\n",
        "    ],\n",
        "    max_tokens=60\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Summarize Text  \n",
        "#### Challenge  \n",
        "텍스트 구절의 끝에 'tl; dr :'을 추가하여 텍스트를 요약하십시오.모델이 추가 지침없이 여러 작업을 수행하는 방법을 이해하는 방법에 주목하십시오.TL보다 더 많은 설명 프롬프트를 실험하여 모델의 동작을 수정하고받은 요약을 사용자 정의 할 수 있습니다 (3).\n",
        "\n",
        "최근의 연구는 많은 NLP 작업과 벤치 마크에 대한 상당한 이익을 보여 주었고, 큰 텍스트 코퍼스에서 사전 훈련을 한 후 특정 작업에 미세 조정이 이어졌습니다. 아키텍처에서 일반적으로 작업에 대한 비도시적이지만, 이 방법은 여전히 수만 또는 수만 개의 예제의 작업 별 미세 조정 데이터 세트가 필요합니다. 대조적으로, 인간은 일반적으로 몇 가지 예 또는 간단한 지침에서 새로운 언어 작업을 수행 할 수 있습니다. 현재 NLP 시스템은 여전히 여전히 어려움을 겪고 있습니다. 여기서 우리는 언어 모델을 스케일링하면 작업에도 적합하지 않은 소수의 성능이 크게 향상되며 때로는 최첨단 미세 조정 접근법과 경쟁력에 도달합니다.\n",
        "\n",
        "Tl;dr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Exercises for several use cases  \n",
        "1. Summarize Text  \n",
        "2. Classify Text  \n",
        "3. Generate New Product Names\n",
        "4. Embeddings\n",
        "5. Fine tune a classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674495198534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n",
        "\n",
        "model = \"first\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674495201868
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      },\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"Pre-training language models on large text corpora followed by fine-tuning on specific tasks has shown substantial gains in NLP tasks. However, humans can perform new language tasks with few examples or simple instructions, which current NLP systems struggle to do. Scaling up language models can improve task-agnostic few\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1689164175,\n",
            "  \"id\": \"chatcmpl-7bT3PSmq5fSao0KcVw6YGT6LHTDJ9\",\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"prompt_annotations\": [\n",
            "    {\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      },\n",
            "      \"prompt_index\": 0\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 60,\n",
            "    \"prompt_tokens\": 137,\n",
            "    \"total_tokens\": 197\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#Setting a few additional, typical parameters during API Call\n",
        "response = openai.ChatCompletion.create(\n",
        "  engine=model,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0.7,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674495223936
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Pre-training language models on large text corpora followed by fine-tuning on specific tasks has shown substantial gains in NLP tasks. However, humans can perform new language tasks with few examples or simple instructions, which current NLP systems struggle to do. Scaling up language models can improve task-agnostic few'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Classify Text  \n",
        "#### Challenge  \n",
        "추론 시간에 제공된 범주로 항목을 분류하십시오. 다음 예에서는 프롬프트에서 분류 할 범주와 텍스트를 모두 제공합니다 (*Playground_reference).\n",
        "\n",
        "고객 문의 : 안녕하세요, 최근 노트북 키보드의 열쇠 중 하나가 최근에 파산되었으며 교체가 필요합니다.\n",
        "\n",
        "분류 카테고리 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674499424645
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
        "\n",
        "model = \"first\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674499378518
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hardware Support\n"
          ]
        }
      ],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  engine=model,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None)\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Generate New Product Names\n",
        "#### Challenge\n",
        "예제 단어에서 제품 이름을 만듭니다.여기에는 이름을 생성 할 제품에 대한 프롬프트 정보가 포함되어 있습니다.우리는 또한 우리가 받고자하는 패턴을 보여주는 비슷한 예를 제공합니다.또한 임의성과보다 혁신적인 반응을 높이기 위해 온도 값을 높게 설정했습니다.\n",
        "\n",
        "제품 설명 : 홈 밀크 쉐이크 제조업체\n",
        "종자 단어 : 빠르고 건강하며 소형.\n",
        "제품 이름 : Homeshaker, Fit Shaker, Quickshake, Shake Maker\n",
        "\n",
        "제품 설명 : 발 크기에 맞는 신발 한 쌍.\n",
        "종자 단어 : 적응성, 적합, 옴니 피트."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674257087279
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
        "model = \"gpt-35-turbo-0613\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "InvalidRequestError",
          "evalue": "The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      2\u001b[0m   engine\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      3\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      4\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt},\n\u001b[1;32m      5\u001b[0m   ],\n\u001b[1;32m      6\u001b[0m   temperature\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m   max_tokens\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m   top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m   frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m   presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m   stop\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again."
          ]
        }
      ],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "  engine=model,\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt},\n",
        "  ],\n",
        "  temperature=0.8,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None)\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Embeddings!  \n",
        "이 섹션에서는 임베딩을 검색하고 단어, 문장 및 문서 사이의 유사성을 찾는 방법을 보여줍니다."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Model Taxonomy - Choosing a similarity model\n",
        "~~가장 강력한 모델 (Davinci)을 사용하여 유사성 모델을 선택합시다.~~\n",
        "그러고 싶었으나, 기존 모델이 Legacy 상태로 된 결과 다른 걸 선택합니다.\n",
        "\n",
        "**Model taxonomy**: {family} - {capability} - {input-type} - {identifier}  \n",
        "\n",
        "{family}     --> text-similarity  (general text GPT-3 model)  \n",
        "{capability} --> davincie         (curie is second most powerful in ada-babbage-curie-davinci family)  \n",
        "{input-type} --> n/a              (only specified for search models)  \n",
        "{identifier} --> 001              (version 001)  \n",
        "\n",
        "## ~~model = 'text-similarity-davinci-001'~~ --> 응 안돼!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674256936134
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: plotly in /home/vscode/.local/lib/python3.9/site-packages (5.10.0)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /home/vscode/.local/lib/python3.9/site-packages (from plotly) (8.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn) (1.25.1)\n",
            "Collecting scipy>=1.5.0 (from scikit-learn)\n",
            "  Downloading scipy-1.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.5/36.5 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn) (1.3.1)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
            "Successfully installed scikit-learn-1.3.0 scipy-1.11.1 threadpoolctl-3.1.0\n"
          ]
        }
      ],
      "source": [
        "# Ensure core libriares are installed\n",
        "!pip install plotly scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /home/vscode/.local/lib/python3.9/site-packages (from pandas) (1.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pytz, tzdata, pandas\n",
            "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n"
          ]
        }
      ],
      "source": [
        "# Dependencies for embeddings_utils\n",
        "!pip install matplotlib\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674829364153
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from openai.embeddings_utils import get_embedding, cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674829424097
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text = 'the quick brown fox jumped over the lazy dog'\n",
        "\n",
        "model = 'text-embedding-ada-002'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674829446467
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.004474656656384468,\n",
              " 0.00978652760386467,\n",
              " -0.014904950745403767,\n",
              " -0.006424985360354185,\n",
              " -0.01135313231498003,\n",
              " 0.015513833612203598,\n",
              " -0.02372107096016407,\n",
              " -0.016414472833275795,\n",
              " -0.0158182755112648,\n",
              " -0.029632311314344406,\n",
              " 0.021298224106431007,\n",
              " 0.021095262840390205,\n",
              " 0.018570933490991592,\n",
              " 0.004170214757323265,\n",
              " -0.0007155169150792062,\n",
              " -0.007579326163977385,\n",
              " 0.02521790750324726,\n",
              " -0.004214612767100334,\n",
              " 0.011175542138516903,\n",
              " -0.008587788790464401,\n",
              " -0.009513798169791698,\n",
              " 0.021577294915914536,\n",
              " -0.005993693135678768,\n",
              " -0.008257976733148098,\n",
              " 0.006041261833161116,\n",
              " 0.013040246441960335,\n",
              " 0.007439790293574333,\n",
              " -0.0035169341135770082,\n",
              " -0.008955655619502068,\n",
              " 0.0011939817341044545,\n",
              " 0.00666600139811635,\n",
              " 0.0038657733239233494,\n",
              " -0.039272960275411606,\n",
              " -0.002559211803600192,\n",
              " -0.012761174701154232,\n",
              " -0.0217422004789114,\n",
              " -0.0037072100676596165,\n",
              " -0.010458835400640965,\n",
              " 0.02597901225090027,\n",
              " -0.0456916019320488,\n",
              " 0.009399632923305035,\n",
              " 0.015653369948267937,\n",
              " -0.02261747047305107,\n",
              " -0.01161951944231987,\n",
              " -0.0028573106974363327,\n",
              " 0.012215716764330864,\n",
              " 0.010534945875406265,\n",
              " -0.01253284327685833,\n",
              " -0.0228965412825346,\n",
              " 0.01036369800567627,\n",
              " -0.00026955761131830513,\n",
              " 0.006583548616617918,\n",
              " -0.009919720701873302,\n",
              " -0.011625861749053001,\n",
              " -0.004718843847513199,\n",
              " -0.0072368294931948185,\n",
              " -0.0013802936300635338,\n",
              " -0.006250565405935049,\n",
              " 0.009380605071783066,\n",
              " -0.0057621905580163,\n",
              " 0.010782305151224136,\n",
              " 0.013547648675739765,\n",
              " -0.005140622146427631,\n",
              " -0.005632168613374233,\n",
              " 0.0007163097034208477,\n",
              " -0.009399632923305035,\n",
              " 0.011105773970484734,\n",
              " -0.010534945875406265,\n",
              " -0.013052931055426598,\n",
              " -0.004890092182904482,\n",
              " 0.02935323864221573,\n",
              " -0.001888489001430571,\n",
              " 0.00033754162723198533,\n",
              " 0.005996864289045334,\n",
              " 0.0315350703895092,\n",
              " -0.008784406818449497,\n",
              " -0.027450479567050934,\n",
              " 0.00896834023296833,\n",
              " 0.014499028213322163,\n",
              " 0.01159414928406477,\n",
              " 0.029733791947364807,\n",
              " -0.04188608378171921,\n",
              " -0.006066631991416216,\n",
              " 0.0144609734416008,\n",
              " 0.01740390807390213,\n",
              " 0.002544941147789359,\n",
              " -0.025852160528302193,\n",
              " 0.03785223141312599,\n",
              " -0.017036041244864464,\n",
              " 0.011093088425695896,\n",
              " 0.005644853692501783,\n",
              " 0.030748596414923668,\n",
              " 0.008105755783617496,\n",
              " -0.0055275168269872665,\n",
              " -0.017239002510905266,\n",
              " 0.0063901012763381,\n",
              " -0.0008657556609250605,\n",
              " 0.0192305576056242,\n",
              " -0.010046571493148804,\n",
              " -0.025852160528302193,\n",
              " 0.007040210533887148,\n",
              " -0.011714656837284565,\n",
              " -0.027171408757567406,\n",
              " -0.0031125976238399744,\n",
              " 0.006856277119368315,\n",
              " -0.026790855452418327,\n",
              " -0.005492632742971182,\n",
              " 0.022262288257479668,\n",
              " 0.018063532188534737,\n",
              " -0.014219957403838634,\n",
              " 0.01633836328983307,\n",
              " 0.023416629061102867,\n",
              " 0.018203066661953926,\n",
              " -0.039704252034425735,\n",
              " -0.004090933129191399,\n",
              " -0.011308735236525536,\n",
              " 0.009659676812589169,\n",
              " -0.009444030933082104,\n",
              " -0.009266439825296402,\n",
              " -0.008651213720440865,\n",
              " 0.009380605071783066,\n",
              " 0.017657609656453133,\n",
              " 0.02236376889050007,\n",
              " -0.0024339468218386173,\n",
              " -0.01397894136607647,\n",
              " -0.00952014047652483,\n",
              " -0.0038974860217422247,\n",
              " 0.007141691166907549,\n",
              " -0.011308735236525536,\n",
              " 0.0036945249885320663,\n",
              " 0.03249913454055786,\n",
              " 0.023708386346697807,\n",
              " 0.032905057072639465,\n",
              " -0.012437705881893635,\n",
              " -0.03706575930118561,\n",
              " 0.023695699870586395,\n",
              " 0.0051342798396945,\n",
              " -0.011200912296772003,\n",
              " -0.030241193249821663,\n",
              " -0.02241450920701027,\n",
              " -0.001587218721397221,\n",
              " 0.016414472833275795,\n",
              " -0.006577205844223499,\n",
              " 0.008727324195206165,\n",
              " 0.022452564910054207,\n",
              " 0.024088937789201736,\n",
              " 0.02155192382633686,\n",
              " 0.008708296343684196,\n",
              " -0.0020581516437232494,\n",
              " -0.007090950850397348,\n",
              " 0.0181776974350214,\n",
              " -0.0023292950354516506,\n",
              " 0.029860641807317734,\n",
              " 0.0003857052361126989,\n",
              " 0.00962162110954523,\n",
              " 0.015640685334801674,\n",
              " 0.003875287249684334,\n",
              " 0.0144356032833457,\n",
              " -0.027932511642575264,\n",
              " -0.021628035232424736,\n",
              " 0.023683015257120132,\n",
              " 0.022008586674928665,\n",
              " -0.0004213819920551032,\n",
              " -0.008137469179928303,\n",
              " 0.002119991462677717,\n",
              " 0.031154518947005272,\n",
              " 0.03320949897170067,\n",
              " 0.002744730794802308,\n",
              " 0.008035988546907902,\n",
              " -0.010604714043438435,\n",
              " 0.005102567374706268,\n",
              " 0.03298116847872734,\n",
              " -0.011759054847061634,\n",
              " 0.03754778951406479,\n",
              " 0.002018510829657316,\n",
              " 0.006868962198495865,\n",
              " 0.021704144775867462,\n",
              " -0.0078583974391222,\n",
              " -0.03206784278154373,\n",
              " 0.00159118277952075,\n",
              " 0.0040497067384421825,\n",
              " 0.014219957403838634,\n",
              " 0.03881629556417465,\n",
              " 0.0240508820861578,\n",
              " 0.005204047542065382,\n",
              " 0.022541359066963196,\n",
              " 0.005651195999234915,\n",
              " -0.027602700516581535,\n",
              " -0.007344652432948351,\n",
              " -0.0013327245833352208,\n",
              " 0.008733666501939297,\n",
              " 0.0020835218019783497,\n",
              " -0.01879926584661007,\n",
              " -0.01371255423873663,\n",
              " -0.6864141821861267,\n",
              " -0.029860641807317734,\n",
              " 0.004097275901585817,\n",
              " -0.010833045467734337,\n",
              " 0.02160266414284706,\n",
              " 0.0335393100976944,\n",
              " -0.012323539704084396,\n",
              " -0.010446150787174702,\n",
              " -0.00034368596971035004,\n",
              " 0.03544206917285919,\n",
              " -0.03052026592195034,\n",
              " 0.002197687514126301,\n",
              " 0.004687131382524967,\n",
              " -0.0027272887527942657,\n",
              " -0.009824582375586033,\n",
              " -0.00333934323862195,\n",
              " 0.02719677798449993,\n",
              " -0.022972650825977325,\n",
              " -0.007959878072142601,\n",
              " 0.020854245871305466,\n",
              " 0.004791783168911934,\n",
              " 0.006983127910643816,\n",
              " -0.010978923179209232,\n",
              " 0.0017330968985334039,\n",
              " -0.0051342798396945,\n",
              " 0.011296049691736698,\n",
              " -0.0020407098345458508,\n",
              " 0.005349925719201565,\n",
              " -0.001236000913195312,\n",
              " 0.016972616314888,\n",
              " -0.0020359528716653585,\n",
              " 0.018875375390052795,\n",
              " -0.006488410290330648,\n",
              " 0.005441892426460981,\n",
              " 0.04262181743979454,\n",
              " 0.004484170116484165,\n",
              " -0.005946123972535133,\n",
              " 0.020600544288754463,\n",
              " 0.03978036344051361,\n",
              " 0.05337874963879585,\n",
              " -0.03559429198503494,\n",
              " -0.013623759150505066,\n",
              " 0.0145878242328763,\n",
              " 0.008930285461246967,\n",
              " -0.011511695571243763,\n",
              " 0.0011789181735366583,\n",
              " 0.025471609085798264,\n",
              " 0.01716289296746254,\n",
              " -0.0055877710692584515,\n",
              " -0.0156660545617342,\n",
              " 0.013573018833994865,\n",
              " 0.01778445951640606,\n",
              " 0.01635104790329933,\n",
              " 0.00512159476056695,\n",
              " -0.018101586028933525,\n",
              " 0.02704455703496933,\n",
              " 0.010972580872476101,\n",
              " -0.0004316885897424072,\n",
              " -0.0017441964009776711,\n",
              " -0.002383206505328417,\n",
              " -0.010560316033661366,\n",
              " 0.0014667105861008167,\n",
              " -0.0103446701541543,\n",
              " 0.008676583878695965,\n",
              " -0.022579414770007133,\n",
              " 0.0035232766531407833,\n",
              " -0.007046553306281567,\n",
              " 0.010287587530910969,\n",
              " 0.022097382694482803,\n",
              " -0.014321438036859035,\n",
              " 0.0228458009660244,\n",
              " 0.01986481063067913,\n",
              " -0.010553973726928234,\n",
              " 0.01009731087833643,\n",
              " 0.014638564549386501,\n",
              " 0.01080133207142353,\n",
              " 0.009279124438762665,\n",
              " -0.006564520765095949,\n",
              " -0.011581463739275932,\n",
              " 0.006437669973820448,\n",
              " -0.012158634141087532,\n",
              " -0.0026115376967936754,\n",
              " -0.039272960275411606,\n",
              " -0.0015031801303848624,\n",
              " 0.03567039966583252,\n",
              " 0.017200946807861328,\n",
              " -0.03511225804686546,\n",
              " -0.0064027863554656506,\n",
              " -0.005089882295578718,\n",
              " -0.0241523627191782,\n",
              " 0.016845766454935074,\n",
              " 0.024672450497746468,\n",
              " -0.031890250742435455,\n",
              " -0.0011583049781620502,\n",
              " -0.012431363575160503,\n",
              " 0.0085116783156991,\n",
              " -0.006142742466181517,\n",
              " 0.03848648443818092,\n",
              " 0.0411757193505764,\n",
              " -0.03229617327451706,\n",
              " 0.012298169545829296,\n",
              " -0.0018742182292044163,\n",
              " -0.003532790346071124,\n",
              " -0.004239982925355434,\n",
              " 0.014308752492070198,\n",
              " 0.03046952560544014,\n",
              " 0.016756970435380936,\n",
              " 0.0018076216802001,\n",
              " 0.017429279163479805,\n",
              " -0.011156514286994934,\n",
              " -0.008594131097197533,\n",
              " -0.01754344440996647,\n",
              " 0.017467333003878593,\n",
              " 0.00509622460231185,\n",
              " -0.0064598689787089825,\n",
              " -0.02501494623720646,\n",
              " 0.0156660545617342,\n",
              " -0.004465142730623484,\n",
              " 0.015830960124731064,\n",
              " -0.01947157457470894,\n",
              " 0.009425003081560135,\n",
              " -0.011784425005316734,\n",
              " 0.00889222975820303,\n",
              " -0.0008221507305279374,\n",
              " 0.007655436173081398,\n",
              " 0.001875803922303021,\n",
              " -0.026790855452418327,\n",
              " -0.02935323864221573,\n",
              " -0.015919756144285202,\n",
              " -0.004804468248039484,\n",
              " -0.007458817679435015,\n",
              " 0.02024536207318306,\n",
              " 0.03544206917285919,\n",
              " -0.0024339468218386173,\n",
              " -0.0031268682796508074,\n",
              " -0.0043795183300971985,\n",
              " 0.014422918669879436,\n",
              " 0.006161769852042198,\n",
              " 0.01831723377108574,\n",
              " -0.015970496460795403,\n",
              " -0.0316365510225296,\n",
              " 0.009006395936012268,\n",
              " -0.014296067878603935,\n",
              " -0.013611074537038803,\n",
              " 0.007224144414067268,\n",
              " -0.01991555094718933,\n",
              " -0.025826791301369667,\n",
              " 0.004401717334985733,\n",
              " 0.006646973546594381,\n",
              " 0.03052026592195034,\n",
              " -0.012203032150864601,\n",
              " -0.02313755825161934,\n",
              " -0.012367937713861465,\n",
              " -0.015348928049206734,\n",
              " 0.02285848557949066,\n",
              " -0.0053974948823452,\n",
              " -0.03270209580659866,\n",
              " -0.004297065548598766,\n",
              " -0.004645904991775751,\n",
              " -0.02859213575720787,\n",
              " 0.027704181149601936,\n",
              " 0.01402968168258667,\n",
              " -0.0065328083001077175,\n",
              " -0.00420509884133935,\n",
              " 0.01038906816393137,\n",
              " -0.03534058853983879,\n",
              " 0.0032600616104900837,\n",
              " 0.0228965412825346,\n",
              " -0.024596339091658592,\n",
              " -0.026968447491526604,\n",
              " -0.004877407103776932,\n",
              " -0.02260478399693966,\n",
              " -0.006247394252568483,\n",
              " -0.001054445980116725,\n",
              " -0.01755612902343273,\n",
              " 0.011600491590797901,\n",
              " -0.027171408757567406,\n",
              " -0.024266527965664864,\n",
              " -0.002250013407319784,\n",
              " -0.011074061505496502,\n",
              " -0.004347805865108967,\n",
              " 0.018837321549654007,\n",
              " 0.006434498820453882,\n",
              " -0.022769691422581673,\n",
              " 0.015678739175200462,\n",
              " -0.004877407103776932,\n",
              " 0.02468513511121273,\n",
              " 0.012431363575160503,\n",
              " -0.023987457156181335,\n",
              " -0.01007194072008133,\n",
              " 0.021057207137346268,\n",
              " 0.027298258617520332,\n",
              " 0.01277386024594307,\n",
              " -0.013370057567954063,\n",
              " -0.005537030752748251,\n",
              " -0.02019462175667286,\n",
              " 0.0053974948823452,\n",
              " 0.030190452933311462,\n",
              " 0.01494300551712513,\n",
              " 0.009444030933082104,\n",
              " 0.016186142340302467,\n",
              " -0.007541270926594734,\n",
              " 0.007300254423171282,\n",
              " -0.027019187808036804,\n",
              " 0.022021271288394928,\n",
              " -0.03201710432767868,\n",
              " -0.0016078319167718291,\n",
              " -0.004157529678195715,\n",
              " 0.006031747907400131,\n",
              " -0.00013874289288651198,\n",
              " -0.019991662353277206,\n",
              " 0.0004197963571641594,\n",
              " 0.019420834258198738,\n",
              " -0.03871481493115425,\n",
              " 0.017340483143925667,\n",
              " 0.023898661136627197,\n",
              " -0.012298169545829296,\n",
              " 0.02260478399693966,\n",
              " 0.008657556027173996,\n",
              " -0.012843627482652664,\n",
              " 0.002595681231468916,\n",
              " -0.020473694428801537,\n",
              " 0.015285502187907696,\n",
              " -0.005568743217736483,\n",
              " 0.02227497287094593,\n",
              " 0.024672450497746468,\n",
              " 0.008949313312768936,\n",
              " 0.015564573928713799,\n",
              " 0.0016030750703066587,\n",
              " -0.004119474906474352,\n",
              " -0.023505425080657005,\n",
              " 0.003209321293979883,\n",
              " 0.0170740969479084,\n",
              " 0.017036041244864464,\n",
              " 0.008479965850710869,\n",
              " 0.000265197129920125,\n",
              " 0.0073763648979365826,\n",
              " -0.0108203599229455,\n",
              " 0.014714675024151802,\n",
              " -0.0013795007253065705,\n",
              " 0.018063532188534737,\n",
              " -0.006894332356750965,\n",
              " 0.007763259578496218,\n",
              " -0.014016996137797832,\n",
              " 0.011638546362519264,\n",
              " 0.011600491590797901,\n",
              " 0.029327869415283203,\n",
              " -0.005432378966361284,\n",
              " -0.017226317897439003,\n",
              " 0.006463040132075548,\n",
              " -0.0017441964009776711,\n",
              " -0.0035137629602104425,\n",
              " -0.024456804618239403,\n",
              " 0.02767881006002426,\n",
              " 0.007433447986841202,\n",
              " -0.015120596624910831,\n",
              " 0.020955726504325867,\n",
              " 0.005080368369817734,\n",
              " 0.029251758009195328,\n",
              " 0.025141797959804535,\n",
              " 0.004027507733553648,\n",
              " 0.003006360260769725,\n",
              " 0.00889222975820303,\n",
              " 0.01033832784742117,\n",
              " 0.018685100600123405,\n",
              " -0.0005585392354987562,\n",
              " -0.006405957508832216,\n",
              " 0.013116356916725636,\n",
              " 0.013179781846702099,\n",
              " -0.020308788865804672,\n",
              " -0.02564920112490654,\n",
              " -0.005530687980353832,\n",
              " 0.002032781485468149,\n",
              " -0.01754344440996647,\n",
              " 0.020524434745311737,\n",
              " 0.012989506125450134,\n",
              " -0.035315219312906265,\n",
              " 0.013623759150505066,\n",
              " 0.01869778521358967,\n",
              " 0.020334158092737198,\n",
              " -0.021678775548934937,\n",
              " -0.027399739250540733,\n",
              " -0.006104687228798866,\n",
              " 0.004135331138968468,\n",
              " 0.0038372320123016834,\n",
              " 0.005194534081965685,\n",
              " -0.027932511642575264,\n",
              " -0.0003151445707771927,\n",
              " -0.003237862605601549,\n",
              " 0.022287657484412193,\n",
              " -0.00013160755042918026,\n",
              " -0.004766413010656834,\n",
              " 8.805218385532498e-05,\n",
              " -0.00954551063477993,\n",
              " -0.0090127382427454,\n",
              " -0.013446168042719364,\n",
              " 0.020042402669787407,\n",
              " -0.011207254603505135,\n",
              " 0.000565278169233352,\n",
              " -0.028516024351119995,\n",
              " 0.00834042951464653,\n",
              " -0.0005803416715934873,\n",
              " -0.0072621991857886314,\n",
              " -0.007370022591203451,\n",
              " 0.026308823376893997,\n",
              " -0.0006679479265585542,\n",
              " -0.012964135967195034,\n",
              " -0.0011043933918699622,\n",
              " -0.0009379019611515105,\n",
              " 0.019205188378691673,\n",
              " -0.019788701087236404,\n",
              " -0.01402968168258667,\n",
              " -0.017378538846969604,\n",
              " 0.013573018833994865,\n",
              " 0.0025211565662175417,\n",
              " -0.008955655619502068,\n",
              " -0.020017031580209732,\n",
              " -0.011315077543258667,\n",
              " 0.028186213225126266,\n",
              " 0.010084626264870167,\n",
              " -0.013052931055426598,\n",
              " -0.01628762297332287,\n",
              " -0.00637741619721055,\n",
              " 0.02265552431344986,\n",
              " 0.08037257194519043,\n",
              " 0.020740080624818802,\n",
              " -0.018494823947548866,\n",
              " 0.0133827431127429,\n",
              " 0.019116392359137535,\n",
              " -0.026968447491526604,\n",
              " -0.022769691422581673,\n",
              " -0.00637741619721055,\n",
              " 0.027983251959085464,\n",
              " -0.0181269571185112,\n",
              " -0.003780149156227708,\n",
              " -0.009342550300061703,\n",
              " 0.005977836437523365,\n",
              " -0.007890109904110432,\n",
              " 0.024025512859225273,\n",
              " -0.0073763648979365826,\n",
              " 0.0037420939188450575,\n",
              " -0.008448252454400063,\n",
              " 0.002061323029920459,\n",
              " 0.0016300308052450418,\n",
              " -0.005407008808106184,\n",
              " -0.003770635463297367,\n",
              " 0.0002251598925795406,\n",
              " 0.012190346606075764,\n",
              " -0.014207271859049797,\n",
              " 0.0039799390360713005,\n",
              " -0.002403819700703025,\n",
              " 0.016858451068401337,\n",
              " 0.02816084213554859,\n",
              " -0.029632311314344406,\n",
              " -0.0031649235170334578,\n",
              " 0.0075349281542003155,\n",
              " 0.015780219808220863,\n",
              " 0.006272764410823584,\n",
              " 0.021095262840390205,\n",
              " 0.020524434745311737,\n",
              " -0.005191362462937832,\n",
              " 0.014511713758111,\n",
              " 0.032955799251794815,\n",
              " -0.03166192024946213,\n",
              " 0.011797109618782997,\n",
              " 0.007496872916817665,\n",
              " 0.004591993521898985,\n",
              " 0.004842523485422134,\n",
              " 0.023936716839671135,\n",
              " 0.00018294241453986615,\n",
              " -0.01769566535949707,\n",
              " 0.016566693782806396,\n",
              " 0.005981008056551218,\n",
              " -0.029708420857787132,\n",
              " 0.0364568755030632,\n",
              " -0.005235760472714901,\n",
              " -0.010458835400640965,\n",
              " 0.0021723173558712006,\n",
              " 0.0058985548093914986,\n",
              " 0.02554772049188614,\n",
              " -0.019446203485131264,\n",
              " -0.004338291939347982,\n",
              " -0.012964135967195034,\n",
              " 0.0016744284657761455,\n",
              " -0.01036369800567627,\n",
              " -0.020131196826696396,\n",
              " -0.002717775059863925,\n",
              " -0.009507455863058567,\n",
              " -0.001725168782286346,\n",
              " -0.025484293699264526,\n",
              " -0.011740026995539665,\n",
              " -0.008492650464177132,\n",
              " -0.006837249733507633,\n",
              " -0.01501911599189043,\n",
              " -0.02165340445935726,\n",
              " -0.018291862681508064,\n",
              " -0.01890074647963047,\n",
              " -0.010433465242385864,\n",
              " 0.015082541853189468,\n",
              " 0.030444154515862465,\n",
              " 0.010325642302632332,\n",
              " -0.0013271748321130872,\n",
              " 0.004636391066014767,\n",
              " 0.010579343885183334,\n",
              " -0.016858451068401337,\n",
              " -0.01605929248034954,\n",
              " -0.0008498993120156229,\n",
              " -0.026156602427363396,\n",
              " 0.0026384934317320585,\n",
              " 0.009773842059075832,\n",
              " 0.013725239783525467,\n",
              " -0.006478896830230951,\n",
              " 0.0120254410430789,\n",
              " 0.01193030271679163,\n",
              " 0.010579343885183334,\n",
              " 0.008657556027173996,\n",
              " -0.010573001578450203,\n",
              " 0.005739991553127766,\n",
              " 0.02256673015654087,\n",
              " -0.01072522159665823,\n",
              " 0.01195567287504673,\n",
              " 0.03455411642789841,\n",
              " 0.019078336656093597,\n",
              " -0.0053974948823452,\n",
              " 0.03318412974476814,\n",
              " -0.016756970435380936,\n",
              " 0.0008776478935033083,\n",
              " 8.19574052002281e-05,\n",
              " 0.014511713758111,\n",
              " -0.007553956005722284,\n",
              " 0.029962122440338135,\n",
              " 0.005058169364929199,\n",
              " -0.020321473479270935,\n",
              " -0.033285610377788544,\n",
              " 0.03171266242861748,\n",
              " -0.0057621905580163,\n",
              " 0.014866895973682404,\n",
              " 0.012526500970125198,\n",
              " 0.011004293337464333,\n",
              " 0.015069856308400631,\n",
              " 0.015589944086968899,\n",
              " 0.011238967068493366,\n",
              " -0.0001285353791899979,\n",
              " -0.009767499752342701,\n",
              " -0.008467280305922031,\n",
              " -0.021374333649873734,\n",
              " -0.000982299679890275,\n",
              " 0.02935323864221573,\n",
              " -0.025484293699264526,\n",
              " 0.021387018263339996,\n",
              " -0.004198756534606218,\n",
              " -0.015513833612203598,\n",
              " -0.003520105266943574,\n",
              " 0.0032077357172966003,\n",
              " 0.011720999144017696,\n",
              " 0.007370022591203451,\n",
              " 0.0016379589214920998,\n",
              " -0.009780184365808964,\n",
              " -0.04183534160256386,\n",
              " -0.011238967068493366,\n",
              " -0.0036723262164741755,\n",
              " 0.012456733733415604,\n",
              " -0.013509593904018402,\n",
              " 0.0011694043641909957,\n",
              " -0.03095155768096447,\n",
              " -0.008746352046728134,\n",
              " 0.012431363575160503,\n",
              " -0.04285014793276787,\n",
              " 0.019902866333723068,\n",
              " -0.025636514648795128,\n",
              " -0.0015420281561091542,\n",
              " -0.014118476770818233,\n",
              " -0.0023039248771965504,\n",
              " 0.01402968168258667,\n",
              " -0.015780219808220863,\n",
              " -0.010503233410418034,\n",
              " -0.024609025567770004,\n",
              " -0.015792904421687126,\n",
              " -0.002170731546357274,\n",
              " -0.03572114184498787,\n",
              " 0.0079091377556324,\n",
              " -0.015894385054707527,\n",
              " 0.040516097098588943,\n",
              " 0.0180254764854908,\n",
              " 0.03008897230029106,\n",
              " -0.003612072207033634,\n",
              " 0.004699816461652517,\n",
              " 0.024380693212151527,\n",
              " -0.026816226541996002,\n",
              " -0.0038435745518654585,\n",
              " -0.0016680859262123704,\n",
              " -0.0030158739537000656,\n",
              " -0.016427159309387207,\n",
              " -0.0071036359295248985,\n",
              " 0.029632311314344406,\n",
              " 0.005581428296864033,\n",
              " 0.026587894186377525,\n",
              " 0.018811950460076332,\n",
              " -0.01750538870692253,\n",
              " 0.011137486435472965,\n",
              " -0.003894314868375659,\n",
              " 0.008911257609724998,\n",
              " -0.012203032150864601,\n",
              " -0.016173457726836205,\n",
              " 0.020080456510186195,\n",
              " -0.0058287871070206165,\n",
              " 0.016224198043346405,\n",
              " -0.00724317179992795,\n",
              " -0.008689269423484802,\n",
              " -0.0042082699947059155,\n",
              " 0.010465177707374096,\n",
              " 0.03249913454055786,\n",
              " 0.03726872056722641,\n",
              " 0.006450355052947998,\n",
              " 0.022186176851391792,\n",
              " 0.0006576413288712502,\n",
              " -0.004956688731908798,\n",
              " 0.0048139821738004684,\n",
              " -0.003409111173823476,\n",
              " -0.02694307640194893,\n",
              " -0.0016744284657761455,\n",
              " 0.01082670222967863,\n",
              " 0.0063139908015728,\n",
              " 0.026968447491526604,\n",
              " -0.0011440342059358954,\n",
              " 0.016135402023792267,\n",
              " -0.012919737957417965,\n",
              " 0.024190418422222137,\n",
              " -0.003805519314482808,\n",
              " 0.005419693887233734,\n",
              " -0.0115243811160326,\n",
              " -0.011974700726568699,\n",
              " -0.001221730257384479,\n",
              " -0.025864847004413605,\n",
              " -0.010515918023884296,\n",
              " -0.034833185374736786,\n",
              " -0.0113975303247571,\n",
              " -0.017137521877884865,\n",
              " 0.006215681787580252,\n",
              " 0.01957305520772934,\n",
              " -0.011689286679029465,\n",
              " 0.010541288182139397,\n",
              " -0.014714675024151802,\n",
              " -0.037623900920152664,\n",
              " -0.004607849754393101,\n",
              " 0.001599110895767808,\n",
              " 0.044955868273973465,\n",
              " -0.010408095084130764,\n",
              " 0.007902795448899269,\n",
              " 0.012012756429612637,\n",
              " -0.004401717334985733,\n",
              " 0.0011884319828823209,\n",
              " 0.016262251883745193,\n",
              " 0.012437705881893635,\n",
              " 0.004867893643677235,\n",
              " -0.0006806330056861043,\n",
              " 0.018114272505044937,\n",
              " -0.008594131097197533,\n",
              " -0.005032799206674099,\n",
              " -0.01996629126369953,\n",
              " -0.009291809983551502,\n",
              " -0.02439337968826294,\n",
              " -0.010687166824936867,\n",
              " 0.02795788273215294,\n",
              " 0.0008011410827748477,\n",
              " 0.00036429919418878853,\n",
              " -0.008682926185429096,\n",
              " -0.017657609656453133,\n",
              " -0.0003391272621229291,\n",
              " 0.011232624761760235,\n",
              " -0.015171336941421032,\n",
              " -0.006111030001193285,\n",
              " -0.024621710181236267,\n",
              " -4.697437907452695e-05,\n",
              " -0.04183534160256386,\n",
              " 0.009412317536771297,\n",
              " -0.018964171409606934,\n",
              " 0.0034598512575030327,\n",
              " -0.030621744692325592,\n",
              " -0.01260895375162363,\n",
              " 0.007395392749458551,\n",
              " 0.015323557890951633,\n",
              " -0.027704181149601936,\n",
              " -0.006507438141852617,\n",
              " -0.01874852553009987,\n",
              " 0.012805572710931301,\n",
              " -0.025129113346338272,\n",
              " -0.002119991462677717,\n",
              " 0.013408113270998001,\n",
              " 0.002923907246440649,\n",
              " -0.021945161744952202,\n",
              " -0.019978975877165794,\n",
              " -0.005933438893407583,\n",
              " 0.025332072749733925,\n",
              " -0.014042366296052933,\n",
              " -0.01635104790329933,\n",
              " -0.0061300573870539665,\n",
              " 0.012602611444890499,\n",
              " 0.016947245225310326,\n",
              " -0.019776014611124992,\n",
              " 0.00030107208294793963,\n",
              " -0.028718985617160797,\n",
              " -0.005004257895052433,\n",
              " 0.015577259473502636,\n",
              " 0.021539239212870598,\n",
              " -0.001147205475717783,\n",
              " -0.004157529678195715,\n",
              " 0.00729391211643815,\n",
              " -0.009583566337823868,\n",
              " 0.0025306702591478825,\n",
              " 0.003922855947166681,\n",
              " -0.014016996137797832,\n",
              " 0.009919720701873302,\n",
              " -0.019370093941688538,\n",
              " -0.0006207753322087228,\n",
              " -0.016909191384911537,\n",
              " -0.0015380640979856253,\n",
              " 0.003497906494885683,\n",
              " 0.020904986187815666,\n",
              " 0.00032624401501379907,\n",
              " -0.006970442831516266,\n",
              " 0.024368008598685265,\n",
              " -0.02843991480767727,\n",
              " 0.017480019479990005,\n",
              " -0.030723225325345993,\n",
              " 0.006095173303037882,\n",
              " -0.02502763271331787,\n",
              " 0.007813999429345131,\n",
              " 0.010509575717151165,\n",
              " 0.006463040132075548,\n",
              " 0.01405505184084177,\n",
              " -0.020093142986297607,\n",
              " 0.0032568902242928743,\n",
              " -0.025230593979358673,\n",
              " -0.005223075393587351,\n",
              " -0.0036025582812726498,\n",
              " 0.022871172055602074,\n",
              " -0.024862727150321007,\n",
              " 0.011245309375226498,\n",
              " 0.0003555782022885978,\n",
              " 0.010985265485942364,\n",
              " -0.031611181795597076,\n",
              " -0.0079091377556324,\n",
              " 0.033234868198633194,\n",
              " 0.0014722603373229504,\n",
              " 0.024888096377253532,\n",
              " 0.03597484156489372,\n",
              " -0.02434263937175274,\n",
              " 0.007186089176684618,\n",
              " 0.005543373059481382,\n",
              " 0.009488428011536598,\n",
              " 0.012190346606075764,\n",
              " -0.02260478399693966,\n",
              " -0.008048673160374165,\n",
              " -0.009995831176638603,\n",
              " 0.028313063085079193,\n",
              " 0.0039482261054217815,\n",
              " -0.011270679533481598,\n",
              " -0.011600491590797901,\n",
              " -0.0031236971262842417,\n",
              " -0.016465213149785995,\n",
              " 0.015551889315247536,\n",
              " -0.02318829856812954,\n",
              " -0.0029540343675762415,\n",
              " 0.018063532188534737,\n",
              " 0.0026860623620450497,\n",
              " -0.026486415416002274,\n",
              " 0.011010635644197464,\n",
              " -0.013293947093188763,\n",
              " -0.012298169545829296,\n",
              " -0.013192467391490936,\n",
              " -0.005067683290690184,\n",
              " -0.030215824022889137,\n",
              " -0.01967453584074974,\n",
              " -0.0076364087872207165,\n",
              " 0.0023784495424479246,\n",
              " 0.01373792439699173,\n",
              " -0.01164488960057497,\n",
              " -0.025573089718818665,\n",
              " -0.008727324195206165,\n",
              " -0.007002155762165785,\n",
              " -0.010395410470664501,\n",
              " 0.026410304009914398,\n",
              " 0.0037008675280958414,\n",
              " 0.021107947453856468,\n",
              " -0.0228458009660244,\n",
              " 0.011340447701513767,\n",
              " 0.013890145346522331,\n",
              " -0.012976820580661297,\n",
              " 0.030444154515862465,\n",
              " -0.0127040920779109,\n",
              " -0.009558196179568768,\n",
              " -0.006440841592848301,\n",
              " -0.002129505155608058,\n",
              " -0.0023261236492544413,\n",
              " -0.0010695095406845212,\n",
              " -0.004468313883990049,\n",
              " -0.0108964703977108,\n",
              " 0.004598335828632116,\n",
              " 0.021526554599404335,\n",
              " 0.010833045467734337,\n",
              " 0.011238967068493366,\n",
              " -0.008714639581739902,\n",
              " -0.0001291299849981442,\n",
              " -0.004224126227200031,\n",
              " -0.019116392359137535,\n",
              " 0.007579326163977385,\n",
              " -0.008524362929165363,\n",
              " 0.011175542138516903,\n",
              " -0.0267654862254858,\n",
              " -0.011359475553035736,\n",
              " 0.006513780448585749,\n",
              " -0.011974700726568699,\n",
              " -0.026410304009914398,\n",
              " -0.005882698576897383,\n",
              " 0.017873255535960197,\n",
              " -0.005765361711382866,\n",
              " 0.00962162110954523,\n",
              " -0.022300343960523605,\n",
              " -0.0049249762669205666,\n",
              " -0.010985265485942364,\n",
              " -0.02945471927523613,\n",
              " 0.01397894136607647,\n",
              " -0.013002190738916397,\n",
              " 0.029530830681324005,\n",
              " 0.024723190814256668,\n",
              " -0.011695628985762596,\n",
              " -0.010186106897890568,\n",
              " 0.0007638787501491606,\n",
              " 0.0013168682344257832,\n",
              " -0.013623759150505066,\n",
              " -0.021513869985938072,\n",
              " 0.007129006087779999,\n",
              " -0.016997985541820526,\n",
              " -0.0012264872202649713,\n",
              " -0.02950545959174633,\n",
              " 0.001980455592274666,\n",
              " -0.0230995025485754,\n",
              " 0.006710398942232132,\n",
              " -0.022021271288394928,\n",
              " -0.01515865232795477,\n",
              " -0.01740390807390213,\n",
              " 0.024723190814256668,\n",
              " -0.0084609379991889,\n",
              " -0.02117137238383293,\n",
              " -0.0020851073786616325,\n",
              " -0.022287657484412193,\n",
              " 0.003605729667469859,\n",
              " -0.0010718879057094455,\n",
              " -0.0101924492046237,\n",
              " 0.006742111872881651,\n",
              " 0.003875287249684334,\n",
              " -0.01779714599251747,\n",
              " -0.006526465527713299,\n",
              " -0.00012070631782989949,\n",
              " -0.023302463814616203,\n",
              " -0.012818257324397564,\n",
              " 0.015348928049206734,\n",
              " -0.007027525920420885,\n",
              " 0.02208469808101654,\n",
              " 0.20864394307136536,\n",
              " -0.001875803922303021,\n",
              " 0.005407008808106184,\n",
              " 0.036862798035144806,\n",
              " -0.010592028498649597,\n",
              " 0.030139712616801262,\n",
              " 0.021767569705843925,\n",
              " -0.0037262376863509417,\n",
              " -0.006472554057836533,\n",
              " 0.02578873559832573,\n",
              " -0.0026051951572299004,\n",
              " 0.012907053343951702,\n",
              " -0.021615350618958473,\n",
              " 0.005200876388698816,\n",
              " 0.014854210428893566,\n",
              " 0.008467280305922031,\n",
              " -0.005445064045488834,\n",
              " -0.0027685153763741255,\n",
              " -0.014410233125090599,\n",
              " -0.03031730465590954,\n",
              " -0.014473658986389637,\n",
              " -0.006310819648206234,\n",
              " -0.026841595768928528,\n",
              " -0.004344634711742401,\n",
              " 0.010883784852921963,\n",
              " 0.0192812979221344,\n",
              " -0.0085116783156991,\n",
              " -0.0008475208887830377,\n",
              " 0.03267672657966614,\n",
              " 0.018342602998018265,\n",
              " -0.017391223460435867,\n",
              " -0.0027986422646790743,\n",
              " -0.0115243811160326,\n",
              " 0.02255404368042946,\n",
              " -0.014714675024151802,\n",
              " 0.0078583974391222,\n",
              " 0.016274938359856606,\n",
              " 0.018215753138065338,\n",
              " 0.012399650178849697,\n",
              " -0.003875287249684334,\n",
              " 0.0206893403083086,\n",
              " 0.0012185589876025915,\n",
              " -0.0075666410848498344,\n",
              " -0.015107912011444569,\n",
              " 0.0019408148946240544,\n",
              " 0.0253574438393116,\n",
              " ...]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.Embedding.create(\n",
        "    input=text, engine=model\n",
        ")[\"data\"][0][\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674829555255
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9161762609368851\n",
            "0.8334429695093547\n",
            "0.7820358471285385\n"
          ]
        }
      ],
      "source": [
        "# compare several words\n",
        "automobile_embedding    = openai.Embedding.create(input='automobile', engine=model)[\"data\"][0][\"embedding\"]\n",
        "vehicle_embedding       = openai.Embedding.create(input='vehicle', engine=model)[\"data\"][0][\"embedding\"]\n",
        "dinosaur_embedding      = openai.Embedding.create(input='dinosaur', engine=model)[\"data\"][0][\"embedding\"]\n",
        "stick_embedding         = openai.Embedding.create(input='stick', engine=model)[\"data\"][0][\"embedding\"]\n",
        "\n",
        "print(cosine_similarity(automobile_embedding, vehicle_embedding))\n",
        "print(cosine_similarity(automobile_embedding, dinosaur_embedding))\n",
        "print(cosine_similarity(automobile_embedding, stick_embedding))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Comparing article from cnn daily news dataset\n",
        "source: https://huggingface.co/datasets/cnn_dailymail\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674831122093
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articles</th>\n",
              "      <th>highligths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BREMEN, Germany -- Carlos Alberto, who scored ...</td>\n",
              "      <td>Werder Bremen pay a club record $10.7 million ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(CNN) -- Football superstar, celebrity, fashio...</td>\n",
              "      <td>Beckham has agreed to a five-year contract wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LOS ANGELES, California (CNN) -- Youssif, the ...</td>\n",
              "      <td>Boy on meeting Spider-Man: \"It was my favorite...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            articles  \\\n",
              "0  BREMEN, Germany -- Carlos Alberto, who scored ...   \n",
              "1  (CNN) -- Football superstar, celebrity, fashio...   \n",
              "2  LOS ANGELES, California (CNN) -- Youssif, the ...   \n",
              "\n",
              "                                          highligths  \n",
              "0  Werder Bremen pay a club record $10.7 million ...  \n",
              "1  Beckham has agreed to a five-year contract wit...  \n",
              "2  Boy on meeting Spider-Man: \"It was my favorite...  "
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "cnn_daily_articles = ['BREMEN, Germany -- Carlos Alberto, who scored in FC Porto\\'s Champions League final victory against Monaco in 2004, has joined Bundesliga club Werder Bremen for a club record fee of 7.8 million euros ($10.7 million). Carlos Alberto enjoyed success at FC Porto under Jose Mourinho. \"I\\'m here to win titles with Werder,\" the 22-year-old said after his first training session with his new club. \"I like Bremen and would only have wanted to come here.\" Carlos Alberto started his career with Fluminense, and helped them to lift the Campeonato Carioca in 2002. In January 2004 he moved on to FC Porto, who were coached by José Mourinho, and the club won the Portuguese title as well as the Champions League. Early in 2005, he moved to Corinthians, where he impressed as they won the Brasileirão,but in 2006 Corinthians had a poor season and Carlos Alberto found himself at odds with manager, Emerson Leão. Their poor relationship came to a climax at a Copa Sul-Americana game against Club Atlético Lanús, and Carlos Alberto declared that he would not play for Corinthians again while Leão remained as manager. Since January this year he has been on loan with his first club Fluminense. Bundesliga champions VfB Stuttgart said on Sunday that they would sign a loan agreement with Real Zaragoza on Monday for Ewerthon, the third top Brazilian player to join the German league in three days. A VfB spokesman said Ewerthon, who played in the Bundesliga for Borussia Dortmund from 2001 to 2005, was expected to join the club for their pre-season training in Austria on Monday. On Friday, Ailton returned to Germany where he was the league\\'s top scorer in 2004, signing a one-year deal with Duisburg on a transfer from Red Star Belgrade. E-mail to a friend .',\n",
        "                        '(CNN) -- Football superstar, celebrity, fashion icon, multimillion-dollar heartthrob. Now, David Beckham is headed for the Hollywood Hills as he takes his game to U.S. Major League Soccer. CNN looks at how Bekham fulfilled his dream of playing for Manchester United, and his time playing for England. The world\\'s famous footballer has begun a five-year contract with the Los Angeles Galaxy team, and on Friday Beckham will meet the press and reveal his new shirt number. This week, we take an in depth look at the life and times of Beckham, as CNN\\'s very own \"Becks,\" Becky Anderson, sets out to examine what makes the man tick -- as footballer, fashion icon and global phenomenon. It\\'s a long way from the streets of east London to the Hollywood Hills and Becky charts Beckham\\'s incredible rise to football stardom, a journey that has seen his skills grace the greatest stages in world soccer. She goes in pursuit of the current hottest property on the sports/celebrity circuit in the U.S. and along the way explores exactly what\\'s behind the man with the golden boot. CNN will look back at the life of Beckham, the wonderfully talented youngster who fulfilled his dream of playing for Manchester United, his marriage to pop star Victoria, and the trials and tribulations of playing for England. We\\'ll look at the highs (scoring against Greece), the lows (being sent off during the World Cup), the Man. U departure for the Galacticos of Madrid -- and now the Home Depot stadium in L.A. We\\'ll ask how Beckham and his family will adapt to life in Los Angeles -- the people, the places to see and be seen and the celebrity endorsement. Beckham is no stranger to exposure. He has teamed with Reggie Bush in an Adidas commercial, is the face of Motorola, is the face on a PlayStation game and doesn\\'t need fashion tips as he has his own international clothing line. But what does the star couple need to do to become an accepted part of Tinseltown\\'s glitterati? The road to major league football in the U.S.A. is a well-worn route for some of the world\\'s greatest players. We talk to some of the former greats who came before him and examine what impact these overseas stars had on U.S. soccer and look at what is different now. We also get a rare glimpse inside the David Beckham academy in L.A, find out what drives the kids and who are their heroes. The perception that in the U.S.A. soccer is a \"game for girls\" after the teenage years is changing. More and more young kids are choosing the European game over the traditional U.S. sports. E-mail to a friend .',\n",
        "                        'LOS ANGELES, California (CNN) -- Youssif, the 5-year-old burned Iraqi boy, rounded the corner at Universal Studios when suddenly the little boy hero met his favorite superhero. Youssif has always been a huge Spider-Man fan. Meeting him was \"my favorite thing,\" he said. Spider-Man was right smack dab in front of him, riding a four-wheeler amid a convoy of other superheroes. The legendary climber of buildings and fighter of evil dismounted, walked over to Youssif and introduced himself. Spidey then gave the boy from a far-away land a gentle hug, embracing him in his iconic blue and red tights. He showed Youssif a few tricks, like how to shoot a web from his wrist. Only this time, no web was spun. \"All right Youssif!\" Spider-Man said after the boy mimicked his wrist movement. Other superheroes crowded around to get a closer look. Even the Green Goblin stopped his villainous ways to tell the boy hi. Youssif remained unfazed. He didn\\'t take a liking to Spider-Man\\'s nemesis. Spidey was just too cool. \"It was my favorite thing,\" the boy said later. \"I want to see him again.\" He then felt compelled to add: \"I know it\\'s not the real Spider-Man.\" This was the day of dreams when the boy\\'s nightmares were, at least temporarily, forgotten. He met SpongeBob, Lassie and a 3-year-old orangutan named Archie. The hairy, brownish-red primate took to the boy, grabbing his hand and holding it. Even when Youssif pulled away, Archie would inch his hand back toward the boy\\'s and then snatch it. See Youssif enjoy being a boy again » . The boy giggled inside a play area where sponge-like balls shot out of toy guns. It was a far different artillery than what he was used to seeing in central Baghdad, as recently as a week ago. He squealed with delight and raced around the room collecting as many balls as he could. He rode a tram through the back stages at Universal Studios. At one point, the car shook. Fire and smoke filled the air, debris cascaded down and a big rig skidded toward the vehicle. The boy and his family survived the pretend earthquake unscathed. \"Even I was scared,\" the dad said. \"Well, I wasn\\'t,\" Youssif replied. The father and mother grinned from ear to ear throughout the day. Youssif pushed his 14-month-old sister, Ayaa, in a stroller. \"Did you even need to ask us if we were interested in coming here?\" Youssif\\'s father said in amazement. \"Other than my wedding day, this is the happiest day of my life,\" he said. Just a day earlier, the mother and father talked about their journey out of Iraq and to the United States. They also discussed that day nine months ago when masked men grabbed their son outside the family home, doused him in gas and set him on fire. His mother heard her boy screaming from inside. The father sought help for his boy across Baghdad, but no one listened. He remembers his son\\'s two months of hospitalization. The doctors didn\\'t use anesthetics. He could hear his boy\\'s piercing screams from the other side of the hospital. Watch Youssif meet his doctor and play with his little sister » . The father knew that speaking to CNN would put his family\\'s lives in jeopardy. The possibility of being killed was better than seeing his son suffer, he said. \"Anything for Youssif,\" he said. \"We had to do it.\" They described a life of utter chaos in Baghdad. Neighbors had recently given birth to a baby girl. Shortly afterward, the father was kidnapped and killed. Then, there was the time when some girls wore tanktops and jeans. They were snatched off the street by gunmen. The stories can be even more gruesome. The couple said they had heard reports that a young girl was kidnapped and beheaded --and her killers sewed a dog\\'s head on the corpse and delivered it to her family\\'s doorstep. \"These are just some of the stories,\" said Youssif\\'s mother, Zainab. Under Saddam Hussein, there was more security and stability, they said. There was running water and electricity most of the time. But still life was tough under the dictator, like the time when Zainab\\'s uncle disappeared and was never heard from again after he read a \"religious book,\" she said. Sitting in the parking lot of a Target in suburban Los Angeles, Youssif\\'s father watched as husbands and wives, boyfriends and girlfriends, parents and their children, came and went. Some held hands. Others smiled and laughed. \"Iraq finished,\" he said in what few English words he knows. He elaborated in Arabic: His homeland won\\'t be enjoying such freedoms anytime soon. It\\'s just not possible. Too much violence. Too many killings. His two children have only seen war. But this week, the family has seen a much different side of America -- an outpouring of generosity and a peaceful nation at home. \"It\\'s been a dream,\" the father said. He used to do a lot of volunteer work back in Baghdad. \"Maybe that\\'s why I\\'m being helped now,\" the father said. At Universal Studios, he looked out across the valley below. The sun glistened off treetops and buildings. It was a picturesque sight fit for a Hollywood movie. \"Good America, good America,\" he said in English. E-mail to a friend . CNN\\'s Arwa Damon contributed to this report.'\n",
        "]\n",
        "\n",
        "cnn_daily_article_highlights = ['Werder Bremen pay a club record $10.7 million for Carlos Alberto .\\nThe Brazilian midfielder won the Champions League with FC Porto in 2004 .\\nSince January he has been on loan with his first club, Fluminense .',\n",
        "                                'Beckham has agreed to a five-year contract with Los Angeles Galaxy .\\nNew contract took effect July 1, 2007 .\\nFormer English captain to meet press, unveil new shirt number Friday .\\nCNN to look at Beckham as footballer, fashion icon and global phenomenon .',\n",
        "                                'Boy on meeting Spider-Man: \"It was my favorite thing\"\\nYoussif also met SpongeBob, Lassie and an orangutan at Universal Studios .\\nDad: \"Other than my wedding day, this is the happiest day of my life\"' \n",
        "]\n",
        "\n",
        "cnn_df = pd.DataFrame({\"articles\":cnn_daily_articles, \"highligths\":cnn_daily_article_highlights})\n",
        "\n",
        "cnn_df.head()                      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1674831294043
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7621254342360414\n",
            "0.7103234824922888\n",
            "0.6754791700917779\n",
            "0.6913856161284869\n"
          ]
        }
      ],
      "source": [
        "article1_embedding    = openai.Embedding.create(input=cnn_df.articles.iloc[0], engine=model)[\"data\"][0][\"embedding\"]\n",
        "article2_embedding    = openai.Embedding.create(input=cnn_df.articles.iloc[1], engine=model)[\"data\"][0][\"embedding\"]\n",
        "article3_embedding    = openai.Embedding.create(input=cnn_df.articles.iloc[2], engine=model)[\"data\"][0][\"embedding\"]\n",
        "\n",
        "highligth1_embedding  = openai.Embedding.create(input=cnn_df.highligths.iloc[0], engine=model)[\"data\"][0][\"embedding\"]\n",
        "highligth2_embedding  = openai.Embedding.create(input=cnn_df.highligths.iloc[1], engine=model)[\"data\"][0][\"embedding\"]\n",
        "highligth3_embedding  = openai.Embedding.create(input=cnn_df.highligths.iloc[2], engine=model)[\"data\"][0][\"embedding\"]\n",
        "\n",
        "print(cosine_similarity(article1_embedding, article2_embedding))\n",
        "print(cosine_similarity(article1_embedding, article3_embedding))\n",
        "\n",
        "print(cosine_similarity(highligth1_embedding, highligth3_embedding))\n",
        "print(cosine_similarity(article1_embedding, highligth3_embedding))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# References  \n",
        "-Azure Reference Documentation  \n",
        "-Azure OpenAI GitHub Repo\n",
        "-cookbooks  \n",
        "-OpenAI website  \n",
        "\n",
        "1 - [Openai Cookbook](https://github.com/openai/openai-cookbook)  \n",
        "2 - [Azure Documentation - Azure Open AI Models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models)  \n",
        "3 - [OpenAI Studio Examples](https://oai.azure.com/portal)  \n",
        "4 - [[PUBLIC] Best practices for fine-tuning GPT-3 to classify text](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# For More Help  \n",
        "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)  \n",
        "AI Specialized CSAs [aka.ms/airangers](aka.ms/airangers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Contributors\n",
        "* Brandon Cowen\n",
        "* Ashish Chauhun\n",
        "* Louis Li  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
